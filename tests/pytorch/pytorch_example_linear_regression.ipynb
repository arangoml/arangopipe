{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ch_data_loader import CH_Dataset\n",
    "from ch_linear_regression_model import CH_LinearRegression\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import jsonpickle\n",
    "from arangopipe.arangopipe_storage.arangopipe_api import ArangoPipe\n",
    "from arangopipe.arangopipe_storage.arangopipe_admin_api import ArangoPipeAdmin\n",
    "from arangopipe.arangopipe_storage.arangopipe_config import ArangoPipeConfig\n",
    "import uuid\n",
    "import datetime\n",
    "from arangopipe.arangopipe_storage.managed_service_conn_parameters import ManagedServiceConnParam\n",
    "import yaml\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the config file with the connection information to Arangopipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_config():\n",
    "    file_name = os.path.join(os.path.abspath(''),\n",
    "                             \"../test_config/test_datagen_config.yaml\")\n",
    "    with open(file_name, \"r\") as file_descriptor:\n",
    "        test_cfg = yaml.load(file_descriptor, Loader=yaml.FullLoader)\n",
    "\n",
    "    return test_cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_driver():\n",
    "\n",
    "    params = {'batch_size': 128, 'shuffle': True, 'num_workers': 6}\n",
    "    trng_dataset = CH_Dataset()\n",
    "    test_dataset = CH_Dataset(train=False)\n",
    "    training_generator = data.DataLoader(trng_dataset, **params)\n",
    "    test_generator = data.DataLoader(test_dataset, **params)\n",
    "    input_size = trng_dataset.input_size\n",
    "    output_size = trng_dataset.output_size\n",
    "\n",
    "    m = CH_LinearRegression(inputSize=input_size, outputSize=output_size)\n",
    "    cost_func = nn.MSELoss()\n",
    "    learning_rate = 0.1\n",
    "    optimizer = torch.optim.Adam(m.parameters(), lr=learning_rate)\n",
    "    all_losses = []\n",
    "    test_pred_list = []\n",
    "    test_acts_list = []\n",
    "    num_epochs = 100\n",
    "    loss_sched = {}\n",
    "    for e in range(num_epochs):\n",
    "        batch_losses = []\n",
    "        for ix, (Xb, yb) in enumerate(training_generator):\n",
    "            _X = Variable(Xb).float()\n",
    "\n",
    "            _y = Variable(yb).float()\n",
    "            #==========Forward pass===============\n",
    "            preds = m(_X)\n",
    "            preds = torch.flatten(preds)\n",
    "            loss = cost_func(preds, _y)\n",
    "\n",
    "            #==========backward pass==============\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_losses.append(loss.item())\n",
    "            all_losses.append(loss.item())\n",
    "\n",
    "        mbl = sqrt(np.mean(batch_losses))\n",
    "\n",
    "        if e % 5 == 0:\n",
    "            print(\"training loss: \" + str(mbl))\n",
    "            loss_sched[e] = mbl\n",
    "\n",
    "    # prepares model for inference when trained with a dropout layer\n",
    "\n",
    "\n",
    "#    print(m.training)\n",
    "#    m.eval()\n",
    "#    print(m.training)\n",
    "\n",
    "    test_batch_losses = []\n",
    "    test_pred_list = []\n",
    "    test_acts_list = []\n",
    "    for _X, _y in test_generator:\n",
    "\n",
    "        _X = Variable(_X).float()\n",
    "        _y = Variable(_y).float()\n",
    "\n",
    "        #apply model\n",
    "        test_preds = m(_X)\n",
    "        test_preds = torch.flatten(test_preds)\n",
    "        test_loss = cost_func(test_preds, _y)\n",
    "        test_pred_list.extend(test_preds.detach().numpy().ravel())\n",
    "        test_acts_list.extend(_y.numpy().ravel())\n",
    "\n",
    "        test_batch_losses.append(test_loss.item())\n",
    "    # print(\"Batch loss: {}\".format(test_loss.item()))\n",
    "\n",
    "    tmbl = sqrt(np.mean(test_batch_losses))\n",
    "    print(\"test loss: \" + str(tmbl))\n",
    "\n",
    "    # Store experiment results in Arangopipe\n",
    "    conn_config = ArangoPipeConfig()\n",
    "    msc = ManagedServiceConnParam()\n",
    "    test_cfg = get_test_config()\n",
    "    conn_params = { msc.DB_SERVICE_HOST : test_cfg['arangodb'][msc.DB_SERVICE_HOST], \\\n",
    "msc.DB_SERVICE_END_POINT : test_cfg['arangodb'][msc.DB_SERVICE_END_POINT],\\\n",
    "msc.DB_SERVICE_NAME : test_cfg['arangodb'][msc.DB_SERVICE_NAME],\\\n",
    "msc.DB_SERVICE_PORT : test_cfg['arangodb'][msc.DB_SERVICE_PORT],\\\n",
    "msc.DB_CONN_PROTOCOL : test_cfg['arangodb'][msc.DB_CONN_PROTOCOL]}\n",
    "    #    conn_params = { msc.DB_SERVICE_HOST : \"localhost\", \\\n",
    "    #                        msc.DB_SERVICE_END_POINT : \"apmdb\",\\\n",
    "    #                        msc.DB_SERVICE_NAME : \"createDB\",\\\n",
    "    #                        msc.DB_SERVICE_PORT : 8529,\\\n",
    "    #                        msc.DB_CONN_PROTOCOL : 'http',\\\n",
    "    #                        msc.DB_NOTIFICATION_EMAIL : 'somebody@some_company.com'}\n",
    "\n",
    "    conn_config = conn_config.create_connection_config(conn_params)\n",
    "    proj_info = {\"name\": \"Housing_Price_Estimation_Project\"}\n",
    "    admin = ArangoPipeAdmin(reuse_connection=False, config=conn_config)\n",
    "    proj_reg = admin.register_project(proj_info)\n",
    "    ap_config = admin.get_config()\n",
    "    ap = ArangoPipe(config=ap_config)\n",
    "    ruuid = str(uuid.uuid4().int)\n",
    "    model_name = \"pytorch-linear-reg\" + \"_dev_run_\" + ruuid\n",
    "    model_info = {\"name\": model_name, \"type\": \"model-development\"}\n",
    "    model_reg = ap.register_model(model_info,\n",
    "                                  project=\"Housing_Price_Estimation_Project\")\n",
    "    ds_info = trng_dataset.get_dataset()\n",
    "    ds_reg = ap.register_dataset(ds_info)\n",
    "    fs = trng_dataset.get_featureset()\n",
    "    fs_reg = ap.register_featureset(fs, ds_reg[\"_key\"])\n",
    "\n",
    "    model_params = {\"optimizer\": \"Adam\", \"training_epochs\": 100,\\\n",
    "                    \"batch_size\": 128, \"learning_rate\": learning_rate,\\\n",
    "                    \"run_id\": ruuid}\n",
    "    model_perf = {\"training_loss_schedule\": jsonpickle.encode(loss_sched),\\\n",
    "                  \"run_id\": ruuid, \"timestamp\":    str(datetime.datetime.now())}\n",
    "    run_tag = \"Housing-Price-Pytorch-Experiment\" + \"_dev_run_\" + ruuid\n",
    "    run_info = {\"dataset\" : ds_reg[\"_key\"],\\\n",
    "                    \"featureset\": fs_reg[\"_key\"],\\\n",
    "                    \"run_id\": ruuid,\\\n",
    "                    \"model\": model_reg[\"_key\"],\\\n",
    "                    \"model-params\": model_params,\\\n",
    "                    \"model-perf\": model_perf,\\\n",
    "                    \"tag\": run_tag,\\\n",
    "                    \"project\": \"Housing Price Estimation Project\"}\n",
    "    ap.log_run(run_info)\n",
    "    mp = ap.lookup_modelperf(run_tag)\n",
    "    print(\n",
    "        \"A look up of the loss schedule for this experiment in Arangopipe yields:\"\n",
    "    )\n",
    "    print(str(mp[\"training_loss_schedule\"]))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
