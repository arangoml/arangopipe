{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Arangopipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides an overview of **Arangopipe**, a component of ArangoDB for managing metadata from machine learning pipelines. Arangopipe has two API's:\n",
    "1. **arangopipe_api**\n",
    "2. **arangopipe_admin_api**\n",
    "**arangopipe_api** is the set of API used for machine learning metadata management. **arangopipe_admin_api** is the API used to provision users into **Arangopipe**. The following notebook illustrates both these API's. We will illustrate this with a machine learning model to predict house prices. The data is available in the UCI machine learning repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Project\n",
    "Use the admministrative API to register a project with Arangopipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arangopipe.arangopipe_storage.arangopipe_api import ArangoPipe\n",
    "from arangopipe.arangopipe_storage.arangopipe_admin_api import ArangoPipeAdmin\n",
    "from arangopipe.arangopipe_storage.arangopipe_config import ArangoPipeConfig\n",
    "from arangopipe.arangopipe_storage.managed_service_conn_parameters import ManagedServiceConnParam\n",
    "mdb_config = ArangoPipeConfig()\n",
    "msc = ManagedServiceConnParam()\n",
    "conn_params = { msc.DB_SERVICE_HOST : \"localhost\", \\\n",
    "                        msc.DB_SERVICE_END_POINT : \"apmdb\",\\\n",
    "                        msc.DB_SERVICE_NAME : \"createDB\",\\\n",
    "                        msc.DB_SERVICE_PORT : 8529,\n",
    "                        msc.DB_CONN_PROTOCOL : 'http'}\n",
    "        \n",
    "mdb_config = mdb_config.create_connection_config(conn_params)\n",
    "admin = ArangoPipeAdmin(reuse_connection = False, config = mdb_config)\n",
    "ap_config = admin.get_config()\n",
    "ap = ArangoPipe(config = ap_config)\n",
    "proj_info = {\"name\": \"Housing_Price_Estimation_Project\"}\n",
    "proj_reg = admin.register_project(proj_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associate Model with Project\n",
    "This pipeline is going to determine the best regression model to use for the project. We will conduct this experiment with hyperopt. First, however we link the the model developed in this pipeline with the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = {\"name\": \"hyper-param-optimization\",  \"type\": \"hyper-opt-experiment\"}\n",
    "model_reg = ap.register_model(model_info, project = \"Housing_Price_Estimation_Project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Development\n",
    "This notebook illustrates the process of storing pipeline metadata while executing a machine learning pipeline. The objective with this experiment is to determine the best model for the dataset using the **Hyperopt** library. After conducting the experiments, the result is tagged and stored in **Arangopipe**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fp = \"cal_housing.csv\"\n",
    "df = pd.read_csv(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info = {\"name\" : \"california-housing-dataset\",\\\n",
    "            \"description\": \"This dataset lists median house prices in Califoria. Various house features are provided\",\\\n",
    "           \"source\": \"UCI ML Repository\" }\n",
    "ds_reg = ap.register_dataset(ds_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the Featureset Generated from the Dataset\n",
    "A log transformation is required for the median-house value. The feature set generated from the dataset is registered with **Arangopipe**. Note that the featureset is linked to the dataset using the dataset registration obtained from the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df[\"medianHouseValue\"] = df[\"medianHouseValue\"].apply(lambda x: np.log(x))\n",
    "featureset = df.dtypes.to_dict()\n",
    "featureset = {k:str(featureset[k]) for k in featureset}\n",
    "featureset[\"name\"] = \"log_transformed_median_house_value\"\n",
    "fs_reg = ap.register_featureset(featureset, ds_reg[\"_key\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "preds = df.columns.tolist()\n",
    "preds.remove(\"medianHouseValue\")\n",
    "X = df[preds]\n",
    "Y = df[\"medianHouseValue\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up the Hyperopt Experiment**\n",
    "\n",
    "Define the hyper-opt space. In this case, this represents the various models and their associated parametrizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import neighbors\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "hyper_param_options =     [{\n",
    "        'type': 'lasso',\n",
    "        'alpha': hp.uniform('alpha', 0.0, 1)\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'type': 'randomforest',\n",
    "        'max_depth': hp.choice('max_depth', range(1,5)),\n",
    "        'max_features': hp.choice('max_features', range(1,8)),\n",
    "        'n_estimators': hp.choice('n_estimators', range(1,50))\n",
    "    },\n",
    "    {\n",
    "        'type': 'knn',\n",
    "        'n_neighbors': hp.choice('knn_n_neighbors', range(1,20))\n",
    "    }\n",
    "]\n",
    "space = hp.choice('regressor_type', hyper_param_options)\n",
    "\n",
    "def hyperopt_train_test(params):\n",
    "    regressor_type = params['type']\n",
    "    del params['type']\n",
    "    if regressor_type == 'lasso':\n",
    "        reg = linear_model.Lasso(**params)\n",
    "    elif regressor_type == 'randomforest':\n",
    "        reg = RandomForestRegressor(**params)\n",
    "    elif regressor_type == 'knn':\n",
    "        reg = neighbors.KNeighborsRegressor(**params)\n",
    "    else:\n",
    "        return 0\n",
    "    reg.fit(X_train, y_train)\n",
    "    ytest_pred = reg.predict(X_test)\n",
    "    return mean_squared_error(y_test, ytest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the Hyperopt Experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "best = 100\n",
    "def f(params):\n",
    "    global best, count\n",
    "    count += 1\n",
    "    rmse = hyperopt_train_test(params.copy())\n",
    "    if rmse < best:\n",
    "        print ('new best:', rmse, 'using', params['type'])\n",
    "        best = rmse\n",
    "    if count % 250 == 0:\n",
    "        print ('iters:', count, ', acc:', rmse, 'using', params)\n",
    "    return {'loss': rmse, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(f, space, algo=tpe.suggest, max_evals=500, trials=trials)\n",
    "print ('best:', best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Hyperopt Space to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonpickle\n",
    "import uuid\n",
    "ruuid = str(uuid.uuid4().int)\n",
    "frozen_space = jsonpickle.encode(space)\n",
    "model_params = {\"name\": \"Housing_Price_Regression_Model_Params\",\\\n",
    "                \"hyperopt-space\": frozen_space, \"run_id\": ruuid}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Results in Arangopipe\n",
    "Note that we are tagging the run so that we can look up this run by the tag if we need to retrieve it from storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "\n",
    "model_perf = {\"best\": jsonpickle.encode(best), \"run_id\": ruuid, \"timestamp\": str(datetime.datetime.now())}\n",
    "run_info = {\"dataset\" : ds_reg[\"_key\"],\\\n",
    "                    \"featureset\": fs_reg[\"_key\"],\\\n",
    "                    \"run_id\": ruuid,\\\n",
    "                    \"model\": model_reg[\"_key\"],\\\n",
    "                    \"model-params\": model_params,\\\n",
    "                    \"model-perf\": model_perf,\\\n",
    "                    \"tag\": \"Housing-Price-Hyperopt-Experiment\",\\\n",
    "                    \"project\": \"Housing Price Estimation Project\"}\n",
    "ap.log_run(run_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What was the best the model from the previous run?\n",
    "The tag (Housing-Price-Hyperopt-Experiment) that we applied while logging the previous experiment can be used to retrieve the results associated with the previous run. For example, we may be interested in the best model and its parameters from the experiment we just conducted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = ap.lookup_modelperf(\"Housing-Price-Hyperopt-Experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note about lookups:\n",
    "Check the return value of the lookup to see if you got a reference to what you were looking for. If what you are looking for was not found, you will get a \"None\" for the return value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = ap.lookup_modelperf(\"A non existent experiment in the database\")\n",
    "mp == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = ap.lookup_modelperf(\"Housing-Price-Hyperopt-Experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp[\"best\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Modeling Option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have the need to extend or customize the arangopipe schema, the API provides that capability. You can add vertex types and edge types. In the context of this (hyperparameter experiment) notebook, the following example serves to illustrate this. If we want to save meta-data about notebooks used for a project to a new graph vertex type, and, link the project to notebooks created for the project, the following code segment illustrates how this can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_info = {\"version\": \"v1\", \"author\": \"John Doe\", \"name\": \"hyperopt_integration.ipynb\"}\n",
    "if not admin.has_vertex('notebook'):\n",
    "    admin.add_vertex_to_arangopipe('notebook')\n",
    "nb_info = ap.insert_into_vertex_type('notebook', notebook_info)\n",
    "if not admin.has_edge('project_notebook'):\n",
    "    admin.add_edge_definition_to_arangopipe('project_notebook', 'project', 'notebook')\n",
    "ap.insert_into_edge_type('project_notebook', proj_reg, nb_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
